{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44156dd8-d91c-4220-a063-511811aea8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytesseract\n",
    "pytesseract.pytesseract.tesseract_cmd = r\"C:\\Program Files\\Tesseract-OCR\\tesseract.exe\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d431aebf-a67e-47bd-80f9-53854c3311a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyPDF2 import PdfReader\n",
    "from docx import Document\n",
    "from pptx import Presentation\n",
    "\n",
    "def extract_from_pdf(file_path):\n",
    "    reader = PdfReader(file_path)\n",
    "    return \" \".join(page.extract_text() for page in reader.pages if page.extract_text())\n",
    "\n",
    "def extract_from_docx(file_path):\n",
    "    doc = Document(file_path)\n",
    "    return \" \".join(p.text for p in doc.paragraphs)\n",
    "\n",
    "def extract_from_pptx(file_path):\n",
    "    prs = Presentation(file_path)\n",
    "    text = []\n",
    "    for slide in prs.slides:\n",
    "        for shape in slide.shapes:\n",
    "            if hasattr(shape, \"text\"):\n",
    "                text.append(shape.text)\n",
    "    return \" \".join(text)\n",
    "\n",
    "def extract_from_txt(file_path):\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return f.read()\n",
    "\n",
    "def extract_from_md(file_path):\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return f.read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "16f0dcbb-d412-4d61-8753-38d92cd8cac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytesseract\n",
    "from PIL import Image, ImageEnhance, ImageFilter\n",
    "import ffmpeg\n",
    "from pydub import AudioSegment\n",
    "import speech_recognition as sr\n",
    "from yt_dlp import YoutubeDL\n",
    "import os\n",
    "\n",
    "# Extract text from image\n",
    "def extract_from_image(file_path):\n",
    "    try:\n",
    "       img = Image.open(file_path)\n",
    "        img = img.convert(\"L\")  # grayscale\n",
    "        img = img.filter(ImageFilter.SHARPEN)\n",
    "        text = pytesseract.image_to_string(img, config='--psm 6')\n",
    "        return text.strip()\n",
    "    except Exception as e:\n",
    "        return f\"Error extracting text from image: {e}\"\n",
    "\n",
    "# Extract text from audio/video\n",
    "def extract_from_audio_video(file_path):\n",
    "    try:\n",
    "        audio_path = \"temp_audio.wav\"\n",
    "\n",
    "        # Convert video to audio (if it's a video file)\n",
    "        if file_path.lower().endswith(('.mp4', '.avi', '.mov', '.mkv')):\n",
    "            print(\"Extracting audio from video...\")\n",
    "            (\n",
    "                ffmpeg\n",
    "                .input(file_path)\n",
    "                .output(audio_path, format='wav', acodec='pcm_s16le', ac=1, ar='16000')\n",
    "                .overwrite_output()\n",
    "                .run(quiet=True)\n",
    "            )\n",
    "            file_path = audio_path  # Update file_path\n",
    "\n",
    "        # Transcribe audio\n",
    "        print(\"Transcribing audio...\")\n",
    "        r = sr.Recognizer()\n",
    "        with sr.AudioFile(file_path) as source:\n",
    "            audio = r.record(source)\n",
    "            text = r.recognize_google(audio)\n",
    "        return text\n",
    "    except Exception as e:\n",
    "        return f\"Error transcribing audio/video: {e}\"\n",
    "\n",
    "# Download YouTube video (optional)\n",
    "def download_youtube_video(url, output_path=\"downloaded_video.mp4\"):\n",
    "    try:\n",
    "        ydl_opts = {'outtmpl': output_path, 'format': 'mp4'}\n",
    "        with YoutubeDL(ydl_opts) as ydl:\n",
    "            ydl.download([url])\n",
    "        return output_path\n",
    "    except Exception as e:\n",
    "        return f\"Error downloading YouTube video: {e}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f9124ed-f381-4fb1-8a1f-e9b45f9b7a7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è Detected incorrect 'ffmpeg' package. Fixing it now...\n",
      "‚úÖ Installed the correct ffmpeg-python package. Please restart the kernel.\n"
     ]
    }
   ],
   "source": [
    "# --- FFmpeg sanity check ---\n",
    "import importlib\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "def ensure_ffmpeg_python():\n",
    "    \"\"\"\n",
    "    Ensures that the correct ffmpeg-python library is installed and not the broken 'ffmpeg' one.\n",
    "    Automatically uninstalls the wrong version and installs the correct one if needed.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        ffmpeg = importlib.import_module(\"ffmpeg\")\n",
    "        # Check if this module has the correct 'input' attribute\n",
    "        if not hasattr(ffmpeg, \"input\"):\n",
    "            print(\"‚ö†Ô∏è Detected incorrect 'ffmpeg' package. Fixing it now...\")\n",
    "            subprocess.check_call([sys.executable, \"-m\", \"pip\", \"uninstall\", \"-y\", \"ffmpeg\"])\n",
    "            subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"ffmpeg-python\"])\n",
    "            print(\"‚úÖ Installed the correct ffmpeg-python package. Please restart the kernel.\")\n",
    "        else:\n",
    "            print(\"‚úÖ ffmpeg-python is correctly installed and ready to use.\")\n",
    "    except ModuleNotFoundError:\n",
    "        print(\"‚öôÔ∏è ffmpeg not found. Installing ffmpeg-python...\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"ffmpeg-python\"])\n",
    "        print(\"‚úÖ Installed ffmpeg-python successfully. Please restart the kernel.\")\n",
    "\n",
    "# Run the check automatically\n",
    "ensure_ffmpeg_python()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d6928f80-840b-47d6-a428-7a4b04cb386c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Added to knowledge base: GenAI.pdf\n",
      "\n",
      "‚úÖ Added to knowledge base: Forest.docx\n",
      "\n",
      "‚úÖ Added to knowledge base: Music.txt\n",
      "\n",
      "‚úÖ Added to knowledge base: quote.png\n",
      "üé¨ Converting VandeMataram.mp3 to WAV...\n",
      "\n",
      "‚úÖ Added to knowledge base: VandeMataram.mp3\n",
      "üé¨ Converting SnowGeese.mp4 to WAV...\n",
      "\n",
      "‚úÖ Added to knowledge base: SnowGeese.mp4\n",
      "üì• Downloading YouTube video from: https://youtu.be/domCDwp5u3I?si=h23FlnVK6yn_CcTc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [youtube] Falling back to generic n function search\n",
      "         player = https://www.youtube.com/s/player/87644c66/player_ias.vflset/en_US/base.js\n",
      "WARNING: [youtube] domCDwp5u3I: nsig extraction failed: Some formats may be missing\n",
      "         n = yxgkK2O8ORfV0ZqDayq ; player = https://www.youtube.com/s/player/87644c66/player_ias.vflset/en_US/base.js\n",
      "         Please report this issue on  https://github.com/yt-dlp/yt-dlp/issues?q= , filling out the appropriate issue template. Confirm you are on the latest version using  yt-dlp -U\n",
      "WARNING: [youtube] domCDwp5u3I: Some web_safari client https formats have been skipped as they are missing a url. YouTube is forcing SABR streaming for this client. See  https://github.com/yt-dlp/yt-dlp/issues/12482  for more details\n",
      "WARNING: [youtube] domCDwp5u3I: Some web client https formats have been skipped as they are missing a url. YouTube is forcing SABR streaming for this client. See  https://github.com/yt-dlp/yt-dlp/issues/12482  for more details\n",
      "ERROR: You have requested merging of multiple formats but ffmpeg is not installed. Aborting due to --abort-on-error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Added to knowledge base: domCDwp5u3I?si=h23FlnVK6yn_CcTc\n",
      "\n",
      "Current knowledge base:\n",
      "{'C:\\\\Users\\\\sukanya das\\\\OneDrive\\\\Desktop\\\\CSE Project\\\\Multimodal Data Processing using GenAI\\\\data\\\\GenAI.pdf': 'Generative Artificial Intelligence (GenAI)\\nGenerative Artificial Intelligence (GenAI) refers to a class of AI systems capable of creating new\\ncontent, such as text, images, music, and code, by learning from existing data. These models use\\nadvanced machine learning techniques, particularly deep learning, to understand patterns and\\nstructures within data and then generate novel outputs.\\nHow GenAI Works:\\nGenAI models, like GPT (Generative Pre-trained Transformer) and DALL¬∑E, are trained on massive\\ndatasets. They use neural networks with billions of parameters to predict and generate data\\nsequences. For instance, a text-based model predicts the next word in a sentence, while an image\\nmodel generates pixels based on prompts.\\nApplications of GenAI:\\n- Content creation (articles, reports, stories)\\n- Image and video generation\\n- Music composition\\n- Software code generation\\n- Chatbots and virtual assistants\\nBenefits:\\nGenAI enhances productivity, creativity, and accessibility. It allows individuals and organizations to\\nautomate repetitive tasks, generate personalized content, and explore new ideas efficiently.\\nChallenges:\\nDespite its potential, GenAI raises ethical concerns such as misinformation, copyright infringement,\\nand bias. Responsible use, transparency, and regulation are essential to ensure GenAI‚Äôs benefits\\noutweigh its risks.\\nConclusion:\\nGenerative AI represents a revolutionary advancement in technology, bridging the gap between\\nhuman creativity and machine intelligence. Its continued evolution will shape the future of digital\\ninnovation and communication.\\n', 'C:\\\\Users\\\\sukanya das\\\\OneDrive\\\\Desktop\\\\CSE Project\\\\Multimodal Data Processing using GenAI\\\\data\\\\Forest.docx': 'Forest A forest is a large area covered chiefly with trees and undergrowth. Forests are vital for maintaining the ecological balance of the planet. They act as the lungs of the Earth, absorbing carbon dioxide and releasing oxygen. Types of Forests 1. Tropical Rainforests ‚Äì Found near the equator, these forests have high rainfall and biodiversity.\\n2. Temperate Forests ‚Äì Located in temperate zones, they experience distinct seasons.\\n3. Boreal Forests (Taiga) ‚Äì Found in cold regions, dominated by coniferous trees. Importance of Forests Forests play a crucial role in:\\n- Regulating the climate\\n- Preventing soil erosion\\n- Supporting wildlife habitats\\n- Providing resources like timber, medicine, and food\\n- Maintaining the water cycle Deforestation and Conservation Deforestation‚Äîthe large-scale removal of forest cover‚Äîhas severe environmental impacts, including loss of biodiversity, climate change, and soil degradation. Conservation efforts such as afforestation, sustainable logging, and the establishment of protected areas are essential to preserve forest ecosystems for future generations.', 'C:\\\\Users\\\\sukanya das\\\\OneDrive\\\\Desktop\\\\CSE Project\\\\Multimodal Data Processing using GenAI\\\\data\\\\Music.txt': 'Music is the arrangement of sound to create some combination of form, harmony, melody, rhythm, or otherwise expressive content. Music is generally agreed to be a cultural universal that is present in all human societies. Definitions of music vary widely in substance and approach. While scholars agree that music is defined by a small number of specific elements, there is no consensus as to what these necessary elements are. Music is often characterized as a highly versatile medium for expressing human creativity. Diverse activities are involved in the creation of music, and are often divided into categories of composition, improvisation, and performance. Music may be performed using a wide variety of musical instruments, including the human voice. It can also be composed, sequenced, or otherwise produced to be indirectly played mechanically or electronically, such as via a music box, barrel organ, or digital audio workstation software on a computer.\\n\\nMusic often plays a key role in social events and religious ceremonies. The techniques of making music are often transmitted as part of a cultural tradition. Music is played in public and private contexts, highlighted at events such as festivals and concerts for various different types of ensembles. Music is used in the production of other media, such as in soundtracks to films, TV shows, operas, and video games.\\n\\nListening to music is a common means of entertainment. The culture surrounding music extends into areas of academic study, journalism, philosophy, psychology, and therapy. The music industry includes songwriters, performers, sound engineers, producers, tour organizers, distributors of instruments, accessories, and publishers of sheet music and recordings. Technology facilitating the recording and reproduction of music has historically included sheet music, microphones, phonographs, and tape machines, with playback of digital music being a common use for MP3 players, CD players, and smartphones.', 'C:\\\\Users\\\\sukanya das\\\\OneDrive\\\\Desktop\\\\CSE Project\\\\Multimodal Data Processing using GenAI\\\\data\\\\quote.png': \"Error extracting text from image: tesseract is not installed or it's not in your PATH. See README file for more information.\", 'C:\\\\Users\\\\sukanya das\\\\OneDrive\\\\Desktop\\\\CSE Project\\\\Multimodal Data Processing using GenAI\\\\data\\\\VandeMataram.mp3': \"Error transcribing audio/video: module 'ffmpeg' has no attribute 'input'\", 'C:\\\\Users\\\\sukanya das\\\\OneDrive\\\\Desktop\\\\CSE Project\\\\Multimodal Data Processing using GenAI\\\\data\\\\SnowGeese.mp4': \"Error transcribing audio/video: module 'ffmpeg' has no attribute 'input'\", 'https://youtu.be/domCDwp5u3I?si=h23FlnVK6yn_CcTc': 'Error: Could not download or process YouTube video from https://youtu.be/domCDwp5u3I?si=h23FlnVK6yn_CcTc'}\n",
      "\n",
      "üß† Current knowledge base:\n",
      "\n",
      "üîπ C:\\Users\\sukanya das\\OneDrive\\Desktop\\CSE Project\\Multimodal Data Processing using GenAI\\data\\GenAI.pdf:\n",
      "Generative Artificial Intelligence (GenAI)\n",
      "Generative Artificial Intelligence (GenAI) refers to a class of AI systems capable of creating new\n",
      "content, such as text, images, music, and code, by learning from existing data. These models use\n",
      "advanced machine learning techniques, particularly deep learn...\n",
      "\n",
      "üîπ C:\\Users\\sukanya das\\OneDrive\\Desktop\\CSE Project\\Multimodal Data Processing using GenAI\\data\\Forest.docx:\n",
      "Forest A forest is a large area covered chiefly with trees and undergrowth. Forests are vital for maintaining the ecological balance of the planet. They act as the lungs of the Earth, absorbing carbon dioxide and releasing oxygen. Types of Forests 1. Tropical Rainforests ‚Äì Found near the equator, th...\n",
      "\n",
      "üîπ C:\\Users\\sukanya das\\OneDrive\\Desktop\\CSE Project\\Multimodal Data Processing using GenAI\\data\\Music.txt:\n",
      "Music is the arrangement of sound to create some combination of form, harmony, melody, rhythm, or otherwise expressive content. Music is generally agreed to be a cultural universal that is present in all human societies. Definitions of music vary widely in substance and approach. While scholars agre...\n",
      "\n",
      "üîπ C:\\Users\\sukanya das\\OneDrive\\Desktop\\CSE Project\\Multimodal Data Processing using GenAI\\data\\quote.png:\n",
      "Error extracting text from image: tesseract is not installed or it's not in your PATH. See README file for more information....\n",
      "\n",
      "üîπ C:\\Users\\sukanya das\\OneDrive\\Desktop\\CSE Project\\Multimodal Data Processing using GenAI\\data\\VandeMataram.mp3:\n",
      "Error transcribing audio/video: module 'ffmpeg' has no attribute 'input'...\n",
      "\n",
      "üîπ C:\\Users\\sukanya das\\OneDrive\\Desktop\\CSE Project\\Multimodal Data Processing using GenAI\\data\\SnowGeese.mp4:\n",
      "Error transcribing audio/video: module 'ffmpeg' has no attribute 'input'...\n",
      "\n",
      "üîπ https://youtu.be/domCDwp5u3I?si=h23FlnVK6yn_CcTc:\n",
      "Error: Could not download or process YouTube video from https://youtu.be/domCDwp5u3I?si=h23FlnVK6yn_CcTc...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"PATH\"] += os.pathsep + r\"C:\\ffmpeg\\bin\"\n",
    "\n",
    "from yt_dlp import YoutubeDL\n",
    "import ffmpeg\n",
    "from pydub import AudioSegment\n",
    "import speech_recognition as sr\n",
    "from PyPDF2 import PdfReader\n",
    "from docx import Document\n",
    "from pptx import Presentation\n",
    "import pytesseract\n",
    "from PIL import Image, ImageEnhance, ImageFilter\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# üìò --- TEXT EXTRACTION FROM DOCUMENTS ---\n",
    "# -------------------------------------------------------------------\n",
    "def extract_from_pdf(file_path):\n",
    "    reader = PdfReader(file_path)\n",
    "    return \" \".join(page.extract_text() for page in reader.pages if page.extract_text())\n",
    "\n",
    "def extract_from_docx(file_path):\n",
    "    doc = Document(file_path)\n",
    "    return \" \".join(p.text for p in doc.paragraphs)\n",
    "\n",
    "def extract_from_pptx(file_path):\n",
    "    prs = Presentation(file_path)\n",
    "    text = []\n",
    "    for slide in prs.slides:\n",
    "        for shape in slide.shapes:\n",
    "            if hasattr(shape, \"text\"):\n",
    "                text.append(shape.text)\n",
    "    return \" \".join(text)\n",
    "\n",
    "def extract_from_txt(file_path):\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return f.read()\n",
    "\n",
    "def extract_from_md(file_path):\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return f.read()\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# üñºÔ∏è --- IMAGE EXTRACTION ---\n",
    "# -------------------------------------------------------------------\n",
    "def extract_from_image(file_path):\n",
    "    try:\n",
    "        img = Image.open(file_path)\n",
    "        img = img.convert(\"L\")  # grayscale\n",
    "        img = img.filter(ImageFilter.SHARPEN)\n",
    "        text = pytesseract.image_to_string(img, config='--psm 6')\n",
    "        return text.strip()\n",
    "    except Exception as e:\n",
    "        return f\"Error extracting text from image: {e}\"\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# üéß --- AUDIO/VIDEO EXTRACTION ---\n",
    "# -------------------------------------------------------------------\n",
    "def extract_from_audio_video(file_path):\n",
    "    \"\"\"Extracts text from audio or video files using ffmpeg + SpeechRecognition.\"\"\"\n",
    "    try:\n",
    "        audio_path = \"temp_audio.wav\"\n",
    "\n",
    "        # Convert MP3 or video to WAV\n",
    "        if file_path.lower().endswith(('.mp3', '.mp4', '.avi', '.mov', '.mkv')):\n",
    "            print(f\"üé¨ Converting {os.path.basename(file_path)} to WAV...\")\n",
    "            (\n",
    "                ffmpeg\n",
    "                .input(file_path)\n",
    "                .output(audio_path, format='wav', acodec='pcm_s16le', ac=1, ar='16000')\n",
    "                .overwrite_output()\n",
    "                .run(quiet=True)\n",
    "            )\n",
    "            file_path = audio_path\n",
    "\n",
    "        # Transcribe the converted audio\n",
    "        print(\"üéß Transcribing audio...\")\n",
    "        r = sr.Recognizer()\n",
    "        with sr.AudioFile(file_path) as source:\n",
    "            audio = r.record(source)\n",
    "            text = r.recognize_google(audio)\n",
    "        return text\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"Error transcribing audio/video: {e}\"\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# üé• --- YOUTUBE VIDEO HANDLING ---\n",
    "# -------------------------------------------------------------------\n",
    "def download_youtube_video(url, output_path=\"youtube_download.mp4\"):\n",
    "    \"\"\"Download YouTube video using yt_dlp.\"\"\"\n",
    "    try:\n",
    "        print(f\"üì• Downloading YouTube video from: {url}\")\n",
    "        ydl_opts = {\n",
    "            'outtmpl': output_path,\n",
    "            'format': 'bestvideo+bestaudio/best',\n",
    "            'quiet': True\n",
    "        }\n",
    "        with YoutubeDL(ydl_opts) as ydl:\n",
    "            ydl.download([url])\n",
    "        print(\"‚úÖ Download completed.\")\n",
    "        return output_path\n",
    "    except Exception as e:\n",
    "        return f\"Error downloading YouTube video: {e}\"\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# üîç --- FILE TYPE DETECTION ---\n",
    "# -------------------------------------------------------------------\n",
    "def is_youtube_url(url):\n",
    "    return \"youtube.com\" in url or \"youtu.be\" in url\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# üß† --- UNIVERSAL TEXT EXTRACTOR ---\n",
    "# -------------------------------------------------------------------\n",
    "def extract_text_from_file(file_path):\n",
    "    \"\"\"Smart extractor for all file types including YouTube URLs.\"\"\"\n",
    "    if not os.path.exists(file_path) and not is_youtube_url(file_path):\n",
    "        return f\"Error: File not found at {file_path}\"\n",
    "\n",
    "    file_extension = os.path.splitext(file_path)[1].lower()\n",
    "\n",
    "    if file_extension == '.pdf':\n",
    "        return extract_from_pdf(file_path)\n",
    "    elif file_extension == '.docx':\n",
    "        return extract_from_docx(file_path)\n",
    "    elif file_extension == '.pptx':\n",
    "        return extract_from_pptx(file_path)\n",
    "    elif file_extension == '.txt':\n",
    "        return extract_from_txt(file_path)\n",
    "    elif file_extension == '.md':\n",
    "        return extract_from_md(file_path)\n",
    "    elif file_extension in ('.png', '.jpg', '.jpeg'):\n",
    "        return extract_from_image(file_path)\n",
    "    elif file_extension in ('.mp3', '.mp4', '.avi', '.mov', '.mkv'):\n",
    "        return extract_from_audio_video(file_path)\n",
    "    elif is_youtube_url(file_path):\n",
    "        downloaded_video = download_youtube_video(file_path)\n",
    "        if os.path.exists(downloaded_video):\n",
    "            return extract_from_audio_video(downloaded_video)\n",
    "        else:\n",
    "            return f\"Error: Could not download or process YouTube video from {file_path}\"\n",
    "    else:\n",
    "        return f\"Error: Unsupported file type: {file_extension}\"\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# üß© --- ADD TO KNOWLEDGE BASE ---\n",
    "# -------------------------------------------------------------------\n",
    "knowledge_base = {}\n",
    "\n",
    "def add_to_knowledge_base(file_path):\n",
    "    text = extract_text_from_file(file_path)\n",
    "    knowledge_base[file_path] = text\n",
    "    print(f\"\\n‚úÖ Added to knowledge base: {os.path.basename(file_path)}\")\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# üß† --- EXAMPLES ---\n",
    "# -------------------------------------------------------------------\n",
    "add_to_knowledge_base(r\"C:\\Users\\sukanya das\\OneDrive\\Desktop\\CSE Project\\Multimodal Data Processing using GenAI\\data\\GenAI.pdf\")\n",
    "\n",
    "add_to_knowledge_base(r\"C:\\Users\\sukanya das\\OneDrive\\Desktop\\CSE Project\\Multimodal Data Processing using GenAI\\data\\Forest.docx\")\n",
    "\n",
    "add_to_knowledge_base(r\"C:\\Users\\sukanya das\\OneDrive\\Desktop\\CSE Project\\Multimodal Data Processing using GenAI\\data\\Music.txt\")\n",
    "\n",
    "add_to_knowledge_base(r\"C:\\Users\\sukanya das\\OneDrive\\Desktop\\CSE Project\\Multimodal Data Processing using GenAI\\data\\quote.png\")\n",
    "\n",
    "add_to_knowledge_base(r\"C:\\Users\\sukanya das\\OneDrive\\Desktop\\CSE Project\\Multimodal Data Processing using GenAI\\data\\VandeMataram.mp3\")\n",
    "\n",
    "add_to_knowledge_base(r\"C:\\Users\\sukanya das\\OneDrive\\Desktop\\CSE Project\\Multimodal Data Processing using GenAI\\data\\SnowGeese.mp4\")\n",
    "\n",
    "add_to_knowledge_base(\"https://youtu.be/domCDwp5u3I?si=h23FlnVK6yn_CcTc\")\n",
    "\n",
    "\n",
    "\n",
    "# Inspect the knowledge base after adding files\n",
    "print(\"\\nCurrent knowledge base:\")\n",
    "print(knowledge_base)\n",
    "\n",
    "print(\"\\nüß† Current knowledge base:\")\n",
    "for k, v in knowledge_base.items():\n",
    "    print(f\"\\nüîπ {k}:\\n{v[:300]}...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2ffcb40d-09a3-42b2-8a67-8a9c132b6d38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C:\\\\Users\\\\sukanya das\\\\OneDrive\\\\Desktop\\\\CSE Project\\\\Multimodal Data Processing using GenAI\\\\data\\\\VandeMataram.mp3': \"Error transcribing audio/video: module 'ffmpeg' has no attribute 'input'\", 'C:\\\\Users\\\\sukanya das\\\\OneDrive\\\\Desktop\\\\CSE Project\\\\Multimodal Data Processing using GenAI\\\\data\\\\SnowGeese.mp4': \"Error transcribing audio/video: module 'ffmpeg' has no attribute 'input'\", 'https://youtu.be/domCDwp5u3I?si=h23FlnVK6yn_CcTc': 'Error: Could not download or process YouTube video from https://youtu.be/domCDwp5u3I?si=h23FlnVK6yn_CcTc'}\n"
     ]
    }
   ],
   "source": [
    "print(knowledge_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5bd1f27-f988-4e7f-8051-859fd171921a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sukanya das\\AppData\\Roaming\\Python\\Python310\\site-packages\\pydub\\utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚öôÔ∏è Added FFmpeg to PATH: C:\\ffmpeg\\bin\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import ffmpeg\n",
    "import pytesseract\n",
    "from PIL import Image, ImageFilter\n",
    "from PyPDF2 import PdfReader\n",
    "from docx import Document\n",
    "from pptx import Presentation\n",
    "from pydub import AudioSegment\n",
    "import speech_recognition as sr\n",
    "from yt_dlp import YoutubeDL\n",
    "import shutil\n",
    "\n",
    "# --- Ensure ffmpeg is available system-wide ---\n",
    "if not shutil.which(\"ffmpeg\"):\n",
    "    ffmpeg_path = r\"C:\\ffmpeg\\bin\"\n",
    "    os.environ[\"PATH\"] += os.pathsep + ffmpeg_path\n",
    "    print(f\"‚öôÔ∏è Added FFmpeg to PATH: {ffmpeg_path}\")\n",
    "else:\n",
    "    print(f\"‚úÖ FFmpeg found at: {shutil.which('ffmpeg')}\")\n",
    "\n",
    "# --- Extraction functions for different file types ---\n",
    "\n",
    "def extract_from_pdf(file_path):\n",
    "    try:\n",
    "        reader = PdfReader(file_path)\n",
    "        return \" \".join(page.extract_text() for page in reader.pages if page.extract_text())\n",
    "    except Exception as e:\n",
    "        return f\"Error extracting text from PDF: {e}\"\n",
    "\n",
    "def extract_from_docx(file_path):\n",
    "    try:\n",
    "        doc = Document(file_path)\n",
    "        return \" \".join(p.text for p in doc.paragraphs)\n",
    "    except Exception as e:\n",
    "        return f\"Error extracting text from DOCX: {e}\"\n",
    "\n",
    "def extract_from_pptx(file_path):\n",
    "    try:\n",
    "        prs = Presentation(file_path)\n",
    "        text = []\n",
    "        for slide in prs.slides:\n",
    "            for shape in slide.shapes:\n",
    "                if hasattr(shape, \"text\"):\n",
    "                    text.append(shape.text)\n",
    "        return \" \".join(text)\n",
    "    except Exception as e:\n",
    "        return f\"Error extracting text from PPTX: {e}\"\n",
    "\n",
    "def extract_from_txt(file_path):\n",
    "    try:\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            return f.read()\n",
    "    except Exception as e:\n",
    "        return f\"Error reading TXT file: {e}\"\n",
    "\n",
    "def extract_from_md(file_path):\n",
    "    try:\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            return f.read()\n",
    "    except Exception as e:\n",
    "        return f\"Error reading MD file: {e}\"\n",
    "\n",
    "def extract_from_image(file_path):\n",
    "    \"\"\"Improved OCR with preprocessing.\"\"\"\n",
    "    try:\n",
    "        img = Image.open(file_path).convert(\"L\")\n",
    "        img = img.filter(ImageFilter.SHARPEN)\n",
    "        text = pytesseract.image_to_string(img, config='--psm 6')\n",
    "        return text.strip() if text.strip() else \"‚ö†Ô∏è No readable text detected in image.\"\n",
    "    except Exception as e:\n",
    "        return f\"Error extracting text from image: {e}\"\n",
    "\n",
    "def extract_from_audio_video(file_path):\n",
    "    \"\"\"Handles both audio (.mp3, .wav) and video (.mp4, etc.)\"\"\"\n",
    "    try:\n",
    "        audio_path = \"temp_audio.wav\"\n",
    "\n",
    "        # If it's a video ‚Äî extract audio first\n",
    "        if file_path.lower().endswith(('.mp4', '.avi', '.mov', '.mkv')):\n",
    "            print(f\"üé¨ Extracting audio from video: {file_path}\")\n",
    "            (\n",
    "                ffmpeg\n",
    "                .input(file_path)\n",
    "                .output(audio_path, format='wav', acodec='pcm_s16le', ac=1, ar='16000')\n",
    "                .overwrite_output()\n",
    "                .run(quiet=True)\n",
    "            )\n",
    "            file_path = audio_path\n",
    "\n",
    "        elif file_path.lower().endswith(('.mp3', '.m4a', '.ogg')):\n",
    "            print(f\"üéß Converting audio to WAV: {file_path}\")\n",
    "            sound = AudioSegment.from_file(file_path)\n",
    "            sound.export(audio_path, format=\"wav\")\n",
    "            file_path = audio_path\n",
    "\n",
    "        # Transcribe the final WAV file\n",
    "        r = sr.Recognizer()\n",
    "        with sr.AudioFile(file_path) as source:\n",
    "            audio = r.record(source)\n",
    "            text = r.recognize_google(audio)\n",
    "        return text\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"Error transcribing audio/video: {e}\"\n",
    "\n",
    "def download_youtube_video(url, output_path=\"downloaded_video.mp4\"):\n",
    "    \"\"\"Downloads and merges YouTube audio+video with proper ffmpeg linkage.\"\"\"\n",
    "    try:\n",
    "        print(f\"üì• Downloading YouTube video from: {url}\")\n",
    "        ydl_opts = {\n",
    "            'outtmpl': output_path,\n",
    "            'format': 'bestvideo+bestaudio/best',\n",
    "            'merge_output_format': 'mp4',\n",
    "            'ffmpeg_location': shutil.which(\"ffmpeg\") or r\"C:\\ffmpeg\\bin\",\n",
    "            'quiet': True\n",
    "        }\n",
    "        with YoutubeDL(ydl_opts) as ydl:\n",
    "            ydl.download([url])\n",
    "        print(f\"‚úÖ Download complete: {output_path}\")\n",
    "        return output_path\n",
    "    except Exception as e:\n",
    "        return f\"Error downloading YouTube video: {e}\"\n",
    "\n",
    "# --- Helper to detect YouTube URLs ---\n",
    "def is_youtube_url(url):\n",
    "    return \"youtube.com\" in url or \"youtu.be\" in url\n",
    "\n",
    "# --- Main extraction dispatcher ---\n",
    "def extract_text_from_file(file_path):\n",
    "    if not os.path.exists(file_path) and not is_youtube_url(file_path):\n",
    "        return f\"Error: File not found at {file_path}\"\n",
    "\n",
    "    file_extension = os.path.splitext(file_path)[1].lower()\n",
    "\n",
    "    if file_extension == '.pdf':\n",
    "        return extract_from_pdf(file_path)\n",
    "    elif file_extension == '.docx':\n",
    "        return extract_from_docx(file_path)\n",
    "    elif file_extension == '.pptx':\n",
    "        return extract_from_pptx(file_path)\n",
    "    elif file_extension == '.txt':\n",
    "        return extract_from_txt(file_path)\n",
    "    elif file_extension == '.md':\n",
    "        return extract_from_md(file_path)\n",
    "    elif file_extension in ('.png', '.jpg', '.jpeg'):\n",
    "        return extract_from_image(file_path)\n",
    "    elif file_extension in ('.mp3', '.mp4', '.avi', '.mov', '.mkv', '.m4a'):\n",
    "        return extract_from_audio_video(file_path)\n",
    "    elif is_youtube_url(file_path):\n",
    "        video_path = download_youtube_video(file_path)\n",
    "        if os.path.exists(video_path):\n",
    "            return extract_from_audio_video(video_path)\n",
    "        return f\"Error: Could not download or process YouTube video from {file_path}\"\n",
    "    else:\n",
    "        return f\"Error: Unsupported file type: {file_extension}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dff30cb7-b1bb-4599-abaf-e1bc0d612c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "knowledge_base.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1e30dae-be84-42ec-8272-ba86d0d35d98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'ffmpeg' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!ffmpeg -version\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e77626e-b124-4e72-981e-3894cc9066b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "print(shutil.which(\"ffmpeg\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f8f4d349-889c-4b81-8bea-6783d3f2132f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Skipping ffmpeg as it is not installed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: ffmpeg-python in c:\\users\\sukanya das\\appdata\\roaming\\python\\python310\\site-packages (0.2.0)\n",
      "Requirement already satisfied: future in c:\\users\\sukanya das\\appdata\\roaming\\python\\python310\\site-packages (from ffmpeg-python) (1.0.0)\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall ffmpeg -y\n",
    "!pip install ffmpeg-python\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9575c8e0-c6b3-4661-a777-bb39bb07d585",
   "metadata": {},
   "source": [
    "## Creating a function that can handle all supported file types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43a56d6c-ee16-44e0-97e0-4e0330f9d939",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def extract_text_from_file(file_path):\n",
    "    \"\"\"\n",
    "    Extracts text from various file types.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): The path to the input file.\n",
    "\n",
    "    Returns:\n",
    "        str: The extracted text, or an error message if extraction fails or the file type is not supported.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(file_path):\n",
    "        return f\"Error: File not found at {file_path}\"\n",
    "\n",
    "    file_extension = os.path.splitext(file_path)[1].lower()\n",
    "\n",
    "    if file_extension == '.pdf':\n",
    "        return extract_from_pdf(file_path)\n",
    "    elif file_extension == '.docx':\n",
    "        return extract_from_docx(file_path)\n",
    "    elif file_extension == '.pptx':\n",
    "        return extract_from_pptx(file_path)\n",
    "    elif file_extension == '.txt':\n",
    "        return extract_from_txt(file_path)\n",
    "    elif file_extension == '.md':\n",
    "        return extract_from_md(file_path)\n",
    "    elif file_extension in ('.png', '.jpg', '.jpeg'):\n",
    "        return extract_from_image(file_path)\n",
    "    elif file_extension in ('.mp3', '.mp4', '.avi', '.mov', '.mkv'):\n",
    "        return extract_from_audio_video(file_path)\n",
    "    # Add handling for YouTube URLs if needed\n",
    "    elif is_youtube_url(file_path):\n",
    "        video_url = download_youtube_video(file_path)\n",
    "        if video_url:\n",
    "            return extract_from_audio_video(video_url)\n",
    "        else:\n",
    "            return f\"Error: Could not download YouTube video from {file_path}\"\n",
    "    else:\n",
    "        return f\"Error: Unsupported file type: {file_extension}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e587a8b-4dfb-433f-b134-d8253e955fd7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'add_to_knowledge_base' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Add example files to the knowledge base\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Replace these placeholder paths with the actual paths to your files\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[43madd_to_knowledge_base\u001b[49m(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124msukanya das\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mOneDrive\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDesktop\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mCSE Project\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mMultimodal Data Processing using GenAI\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mGenAI.pdf\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      7\u001b[0m add_to_knowledge_base(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124msukanya das\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mOneDrive\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDesktop\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mCSE Project\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mMultimodal Data Processing using GenAI\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mForest.docx\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      9\u001b[0m add_to_knowledge_base(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124msukanya das\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mOneDrive\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDesktop\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mCSE Project\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mMultimodal Data Processing using GenAI\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mMusic.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'add_to_knowledge_base' is not defined"
     ]
    }
   ],
   "source": [
    "# Add example files to the knowledge base\n",
    "# Replace these placeholder paths with the actual paths to your files\n",
    "\n",
    "\n",
    "add_to_knowledge_base(r\"C:\\Users\\sukanya das\\OneDrive\\Desktop\\CSE Project\\Multimodal Data Processing using GenAI\\data\\GenAI.pdf\")\n",
    "\n",
    "add_to_knowledge_base(r\"C:\\Users\\sukanya das\\OneDrive\\Desktop\\CSE Project\\Multimodal Data Processing using GenAI\\data\\Forest.docx\")\n",
    "\n",
    "add_to_knowledge_base(r\"C:\\Users\\sukanya das\\OneDrive\\Desktop\\CSE Project\\Multimodal Data Processing using GenAI\\data\\Music.txt\")\n",
    "\n",
    "add_to_knowledge_base(r\"C:\\Users\\sukanya das\\OneDrive\\Desktop\\CSE Project\\Multimodal Data Processing using GenAI\\data\\quote.png\")\n",
    "\n",
    "add_to_knowledge_base(r\"C:\\Users\\sukanya das\\OneDrive\\Desktop\\CSE Project\\Multimodal Data Processing using GenAI\\data\\VandeMataram.mp3\")\n",
    "\n",
    "add_to_knowledge_base(r\"C:\\Users\\sukanya das\\OneDrive\\Desktop\\CSE Project\\Multimodal Data Processing using GenAI\\data\\SnowGeese.mp4\")\n",
    "\n",
    "add_to_knowledge_base(\"https://youtu.be/domCDwp5u3I?si=h23FlnVK6yn_CcTc\")\n",
    "\n",
    "print(\"Example calls to add_to_knowledge_base have been added. Please uncomment and update the file paths to add your files.\")\n",
    "\n",
    "# Inspect the knowledge base after adding files\n",
    "print(\"\\nCurrent knowledge base:\")\n",
    "print(knowledge_base)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba3afe4-bcea-47d8-9568-f308afa758bf",
   "metadata": {},
   "source": [
    "## Creating a function that uses the Gemini model to answer questions based on the knowledge base:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55d997a0-8b3d-46aa-baf8-7d8939ad0543",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sukanya das\\AppData\\Roaming\\Python\\Python310\\site-packages\\google\\api_core\\_python_version_support.py:266: FutureWarning: You are using a Python version (3.10.6) which Google will stop supporting in new releases of google.api_core once it reaches its end of life (2026-10-04). Please upgrade to the latest Python version, or at least Python 3.11, to continue receiving updates for google.api_core past that date.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os, google.generativeai as genai\n",
    "\n",
    "load_dotenv()\n",
    "genai.configure(api_key=os.getenv(\"GOOGLE_API_KEY\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "787c7c05-fac7-4e9c-89fc-4b770bf779fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_question_with_gemini(query):\n",
    "    \"\"\"\n",
    "    Answers a natural language query using the Gemini model and the knowledge base.\n",
    "\n",
    "    Args:\n",
    "        query (str): The user's query.\n",
    "\n",
    "    Returns:\n",
    "        str: The answer generated by the Gemini model, or an informative message if no relevant information is found.\n",
    "    \"\"\"\n",
    "    # 1. Search the knowledge base for relevant information\n",
    "    relevant_results = search_knowledge_base(query)\n",
    "\n",
    "    if not relevant_results:\n",
    "        return \"I couldn't find any relevant information in the knowledge base to answer your question.\"\n",
    "\n",
    "    # 2. Prepare the context for the Gemini model\n",
    "    context = \"\"\n",
    "    for file_path, text in relevant_results.items():\n",
    "        context += f\"Information from {file_path}:\\n{text}\\n\\n\"\n",
    "\n",
    "    # 3. Formulate the prompt for the Gemini model\n",
    "    prompt = f\"\"\"Using the following information, answer the user's question.\n",
    "If you cannot answer the question based on the provided information, please state that you cannot find the answer in the knowledge base.\n",
    "\n",
    "Information:\n",
    "{context}\n",
    "\n",
    "User's question:\n",
    "{query}\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "    # 4. Get the answer from the Gemini model\n",
    "    try:\n",
    "        response = model.generate_content(prompt)\n",
    "        return response.text\n",
    "    except Exception as e:\n",
    "        return f\"Error generating response from Gemini model: {e}\"\n",
    "\n",
    "# Example usage (you'll need to have added some files to the knowledge_base first)\n",
    "# user_question = \"What is the main topic of the PDF file?\"\n",
    "# gemini_answer = answer_question_with_gemini(user_question)\n",
    "# print(gemini_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256342f6-b569-4e76-b45f-b816453b0b14",
   "metadata": {},
   "source": [
    "## Creating a dictionary to store the extracted text and a function for basic searching:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7ac9e5c-1ed4-40ec-acbc-09febb1da306",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to store extracted text: {file_path: extracted_text}\n",
    "knowledge_base = {}\n",
    "\n",
    "def add_to_knowledge_base(file_path):\n",
    "    \"\"\"Extracts text from a file and adds it to the knowledge base.\"\"\"\n",
    "    extracted_text = extract_text_from_file(file_path)\n",
    "    knowledge_base[file_path] = extracted_text\n",
    "    print(f\"Processed and added {file_path} to the knowledge base.\")\n",
    "\n",
    "def search_knowledge_base(query):\n",
    "    \"\"\"Performs a simple keyword search within the knowledge base.\"\"\"\n",
    "    results = {}\n",
    "    for file_path, text in knowledge_base.items():\n",
    "        if query.lower() in text.lower():\n",
    "            results[file_path] = text # Store the whole text for now, can refine later to show snippets\n",
    "    return results\n",
    "\n",
    "# Example usage (you'll need to replace 'path/to/your/file.pdf' with actual file paths)\n",
    "# add_to_knowledge_base('path/to/your/file1.pdf')\n",
    "# add_to_knowledge_base('path/to/your/file2.txt')\n",
    "#\n",
    "# search_query = \"your search term\"\n",
    "# search_results = search_knowledge_base(search_query)\n",
    "#\n",
    "# if search_results:\n",
    "#     print(f\"Found results for '{search_query}':\")\n",
    "#     for file_path, text in search_results.items():\n",
    "#         print(f\"- {file_path}\")\n",
    "#         # print(f\"  Snippet: {text[:200]}...\") # Uncomment to show snippets\n",
    "# else:\n",
    "#     print(f\"No results found for '{search_query}'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d920309-f36a-494a-8c69-e0d36c2f36e3",
   "metadata": {},
   "source": [
    "## Creating a dictionary to store the extracted text and a function for basic searching:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "22673c17-94b3-46fc-bc0e-e5d47ccf179b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to store extracted text: {file_path: extracted_text}\n",
    "knowledge_base = {}\n",
    "\n",
    "def add_to_knowledge_base(file_path):\n",
    "    \"\"\"Extracts text from a file and adds it to the knowledge base.\"\"\"\n",
    "    extracted_text = extract_text_from_file(file_path)\n",
    "    knowledge_base[file_path] = extracted_text\n",
    "    print(f\"Processed and added {file_path} to the knowledge base.\")\n",
    "\n",
    "def search_knowledge_base(query):\n",
    "    \"\"\"Performs a simple keyword search within the knowledge base.\"\"\"\n",
    "    results = {}\n",
    "    for file_path, text in knowledge_base.items():\n",
    "        if query.lower() in text.lower():\n",
    "            results[file_path] = text # Store the whole text for now, can refine later to show snippets\n",
    "    return results\n",
    "\n",
    "# Example usage (you'll need to replace 'path/to/your/file.pdf' with actual file paths)\n",
    "# add_to_knowledge_base('path/to/your/file1.pdf')\n",
    "# add_to_knowledge_base('path/to/your/file2.txt')\n",
    "#\n",
    "# search_query = \"your search term\"\n",
    "# search_results = search_knowledge_base(search_query)\n",
    "#\n",
    "# if search_results:\n",
    "#     print(f\"Found results for '{search_query}':\")\n",
    "#     for file_path, text in search_results.items():\n",
    "#         print(f\"- {file_path}\")\n",
    "#         # print(f\"  Snippet: {text[:200]}...\") # Uncomment to show snippets\n",
    "# else:\n",
    "#     print(f\"No results found for '{search_query}'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde8d110-08ca-4a69-a57a-e75ef0022cfa",
   "metadata": {},
   "source": [
    "##  Creating a function that uses the Gemini model to answer questions based on the knowledge base:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db1acb97-6aa0-43f4-b604-a4894d8f9323",
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_question_with_gemini(query):\n",
    "    \"\"\"\n",
    "    Answers a natural language query using the Gemini model and the knowledge base.\n",
    "\n",
    "    Args:\n",
    "        query (str): The user's query.\n",
    "\n",
    "    Returns:\n",
    "        str: The answer generated by the Gemini model, or an informative message if no relevant information is found.\n",
    "    \"\"\"\n",
    "    # 1. Search the knowledge base for relevant information\n",
    "    relevant_results = search_knowledge_base(query)\n",
    "\n",
    "    if not relevant_results:\n",
    "        return \"I couldn't find any relevant information in the knowledge base to answer your question.\"\n",
    "\n",
    "    # 2. Prepare the context for the Gemini model\n",
    "    context = \"\"\n",
    "    for file_path, text in relevant_results.items():\n",
    "        context += f\"Information from {file_path}:\\n{text}\\n\\n\"\n",
    "\n",
    "    # 3. Formulate the prompt for the Gemini model\n",
    "    prompt = f\"\"\"Using the following information, answer the user's question.\n",
    "If you cannot answer the question based on the provided information, please state that you cannot find the answer in the knowledge base.\n",
    "\n",
    "Information:\n",
    "{context}\n",
    "\n",
    "User's question:\n",
    "{query}\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "    # 4. Get the answer from the Gemini model\n",
    "    try:\n",
    "        response = model.generate_content(prompt)\n",
    "        return response.text\n",
    "    except Exception as e:\n",
    "        return f\"Error generating response from Gemini model: {e}\"\n",
    "\n",
    "# Example usage (you'll need to have added some files to the knowledge_base first)\n",
    "# user_question = \"What is the main topic of the PDF file?\"\n",
    "# gemini_answer = answer_question_with_gemini(user_question)\n",
    "# print(gemini_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4963dc80-7ddd-4e49-834a-de6a9f924274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\sukanya das\\appdata\\roaming\\python\\python310\\site-packages (1.2.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install python-dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6070afc0-70d9-4dc6-8946-f52c433ceac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting google-generativeai\n",
      "  Downloading google_generativeai-0.8.5-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting google-ai-generativelanguage==0.6.15 (from google-generativeai)\n",
      "  Downloading google_ai_generativelanguage-0.6.15-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting google-api-core (from google-generativeai)\n",
      "  Downloading google_api_core-2.28.1-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting google-api-python-client (from google-generativeai)\n",
      "  Downloading google_api_python_client-2.185.0-py3-none-any.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in c:\\users\\sukanya das\\appdata\\roaming\\python\\python310\\site-packages (from google-generativeai) (2.42.0)\n",
      "Requirement already satisfied: protobuf in c:\\users\\sukanya das\\appdata\\roaming\\python\\python310\\site-packages (from google-generativeai) (5.29.4)\n",
      "Requirement already satisfied: pydantic in c:\\users\\sukanya das\\appdata\\roaming\\python\\python310\\site-packages (from google-generativeai) (2.12.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\sukanya das\\appdata\\roaming\\python\\python310\\site-packages (from google-generativeai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\sukanya das\\appdata\\roaming\\python\\python310\\site-packages (from google-generativeai) (4.15.0)\n",
      "Collecting proto-plus<2.0.0dev,>=1.22.3 (from google-ai-generativelanguage==0.6.15->google-generativeai)\n",
      "  Downloading proto_plus-1.26.1-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting googleapis-common-protos<2.0.0,>=1.56.2 (from google-api-core->google-generativeai)\n",
      "  Downloading googleapis_common_protos-1.71.0-py3-none-any.whl.metadata (9.4 kB)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.18.0 in c:\\users\\sukanya das\\appdata\\roaming\\python\\python310\\site-packages (from google-api-core->google-generativeai) (2.32.3)\n",
      "Collecting grpcio<2.0.0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai)\n",
      "  Downloading grpcio-1.76.0-cp310-cp310-win_amd64.whl.metadata (3.8 kB)\n",
      "Collecting grpcio-status<2.0.0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai)\n",
      "  Downloading grpcio_status-1.76.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: cachetools<7.0,>=2.0.0 in c:\\users\\sukanya das\\appdata\\roaming\\python\\python310\\site-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\sukanya das\\appdata\\roaming\\python\\python310\\site-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\sukanya das\\appdata\\roaming\\python\\python310\\site-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
      "INFO: pip is looking at multiple versions of grpcio-status to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading grpcio_status-1.75.1-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.75.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.74.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.73.1-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.73.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.72.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.72.1-py3-none-any.whl.metadata (1.1 kB)\n",
      "INFO: pip is still looking at multiple versions of grpcio-status to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading grpcio_status-1.71.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sukanya das\\appdata\\roaming\\python\\python310\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sukanya das\\appdata\\roaming\\python\\python310\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sukanya das\\appdata\\roaming\\python\\python310\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sukanya das\\appdata\\roaming\\python\\python310\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2025.1.31)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in c:\\users\\sukanya das\\appdata\\roaming\\python\\python310\\site-packages (from rsa<5,>=3.1.4->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
      "Collecting httplib2<1.0.0,>=0.19.0 (from google-api-python-client->google-generativeai)\n",
      "  Downloading httplib2-0.31.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting google-auth-httplib2<1.0.0,>=0.2.0 (from google-api-python-client->google-generativeai)\n",
      "  Downloading google_auth_httplib2-0.2.0-py2.py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting uritemplate<5,>=3.0.1 (from google-api-python-client->google-generativeai)\n",
      "  Downloading uritemplate-4.2.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: pyparsing<4,>=3.0.4 in c:\\users\\sukanya das\\appdata\\roaming\\python\\python310\\site-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\sukanya das\\appdata\\roaming\\python\\python310\\site-packages (from pydantic->google-generativeai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.4 in c:\\users\\sukanya das\\appdata\\roaming\\python\\python310\\site-packages (from pydantic->google-generativeai) (2.41.4)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\sukanya das\\appdata\\roaming\\python\\python310\\site-packages (from pydantic->google-generativeai) (0.4.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\sukanya das\\appdata\\roaming\\python\\python310\\site-packages (from tqdm->google-generativeai) (0.4.6)\n",
      "Downloading google_generativeai-0.8.5-py3-none-any.whl (155 kB)\n",
      "Downloading google_ai_generativelanguage-0.6.15-py3-none-any.whl (1.3 MB)\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ----------------------- ---------------- 0.8/1.3 MB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.3/1.3 MB 3.8 MB/s  0:00:00\n",
      "Downloading google_api_core-2.28.1-py3-none-any.whl (173 kB)\n",
      "Downloading googleapis_common_protos-1.71.0-py3-none-any.whl (294 kB)\n",
      "Downloading grpcio-1.76.0-cp310-cp310-win_amd64.whl (4.7 MB)\n",
      "   ---------------------------------------- 0.0/4.7 MB ? eta -:--:--\n",
      "   -------- ------------------------------- 1.0/4.7 MB 4.6 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 2.4/4.7 MB 6.1 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 3.4/4.7 MB 5.3 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 4.2/4.7 MB 5.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 4.7/4.7 MB 4.7 MB/s  0:00:00\n",
      "Downloading grpcio_status-1.71.2-py3-none-any.whl (14 kB)\n",
      "Downloading proto_plus-1.26.1-py3-none-any.whl (50 kB)\n",
      "Downloading google_api_python_client-2.185.0-py3-none-any.whl (14.5 MB)\n",
      "   ---------------------------------------- 0.0/14.5 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 1.8/14.5 MB 11.2 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 2.9/14.5 MB 7.0 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 3.1/14.5 MB 6.6 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 4.7/14.5 MB 5.4 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 5.5/14.5 MB 5.2 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 6.6/14.5 MB 5.0 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 7.1/14.5 MB 5.0 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 8.4/14.5 MB 4.9 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 9.2/14.5 MB 4.7 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 10.0/14.5 MB 4.7 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 10.7/14.5 MB 4.6 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 11.5/14.5 MB 4.5 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 12.3/14.5 MB 4.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 13.4/14.5 MB 4.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.2/14.5 MB 4.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 14.5/14.5 MB 4.3 MB/s  0:00:03\n",
      "Downloading google_auth_httplib2-0.2.0-py2.py3-none-any.whl (9.3 kB)\n",
      "Downloading httplib2-0.31.0-py3-none-any.whl (91 kB)\n",
      "Downloading uritemplate-4.2.0-py3-none-any.whl (11 kB)\n",
      "Installing collected packages: uritemplate, proto-plus, httplib2, grpcio, googleapis-common-protos, grpcio-status, google-auth-httplib2, google-api-core, google-api-python-client, google-ai-generativelanguage, google-generativeai\n",
      "\n",
      "   --- ------------------------------------  1/11 [proto-plus]\n",
      "   ------- --------------------------------  2/11 [httplib2]\n",
      "   ---------- -----------------------------  3/11 [grpcio]\n",
      "   ---------- -----------------------------  3/11 [grpcio]\n",
      "   ---------- -----------------------------  3/11 [grpcio]\n",
      "   ---------- -----------------------------  3/11 [grpcio]\n",
      "   -------------- -------------------------  4/11 [googleapis-common-protos]\n",
      "   -------------- -------------------------  4/11 [googleapis-common-protos]\n",
      "   -------------- -------------------------  4/11 [googleapis-common-protos]\n",
      "   -------------- -------------------------  4/11 [googleapis-common-protos]\n",
      "   -------------- -------------------------  4/11 [googleapis-common-protos]\n",
      "   ------------------ ---------------------  5/11 [grpcio-status]\n",
      "   ------------------------- --------------  7/11 [google-api-core]\n",
      "   ------------------------- --------------  7/11 [google-api-core]\n",
      "   ------------------------- --------------  7/11 [google-api-core]\n",
      "   ----------------------------- ----------  8/11 [google-api-python-client]\n",
      "   ----------------------------- ----------  8/11 [google-api-python-client]\n",
      "   ----------------------------- ----------  8/11 [google-api-python-client]\n",
      "   ----------------------------- ----------  8/11 [google-api-python-client]\n",
      "   ----------------------------- ----------  8/11 [google-api-python-client]\n",
      "   ----------------------------- ----------  8/11 [google-api-python-client]\n",
      "   ----------------------------- ----------  8/11 [google-api-python-client]\n",
      "   ----------------------------- ----------  8/11 [google-api-python-client]\n",
      "   ----------------------------- ----------  8/11 [google-api-python-client]\n",
      "   ----------------------------- ----------  8/11 [google-api-python-client]\n",
      "   ----------------------------- ----------  8/11 [google-api-python-client]\n",
      "   ----------------------------- ----------  8/11 [google-api-python-client]\n",
      "   ------------------------------- -------  9/11 [google-ai-generativelanguage]\n",
      "   ------------------------------- -------  9/11 [google-ai-generativelanguage]\n",
      "   ------------------------------- -------  9/11 [google-ai-generativelanguage]\n",
      "   ------------------------------- -------  9/11 [google-ai-generativelanguage]\n",
      "   ------------------------------- -------  9/11 [google-ai-generativelanguage]\n",
      "   ------------------------------- -------  9/11 [google-ai-generativelanguage]\n",
      "   ------------------------------- -------  9/11 [google-ai-generativelanguage]\n",
      "   ------------------------------- -------  9/11 [google-ai-generativelanguage]\n",
      "   ------------------------------- -------  9/11 [google-ai-generativelanguage]\n",
      "   ------------------------------- -------  9/11 [google-ai-generativelanguage]\n",
      "   ------------------------------- -------  9/11 [google-ai-generativelanguage]\n",
      "   ------------------------------- -------  9/11 [google-ai-generativelanguage]\n",
      "   ------------------------------- -------  9/11 [google-ai-generativelanguage]\n",
      "   ------------------------------- -------  9/11 [google-ai-generativelanguage]\n",
      "   ------------------------------- -------  9/11 [google-ai-generativelanguage]\n",
      "   ------------------------------- -------  9/11 [google-ai-generativelanguage]\n",
      "   ------------------------------- -------  9/11 [google-ai-generativelanguage]\n",
      "   ------------------------------- -------  9/11 [google-ai-generativelanguage]\n",
      "   ------------------------------- -------  9/11 [google-ai-generativelanguage]\n",
      "   ------------------------------- -------  9/11 [google-ai-generativelanguage]\n",
      "   ------------------------------- -------  9/11 [google-ai-generativelanguage]\n",
      "   ------------------------------------ --- 10/11 [google-generativeai]\n",
      "   ------------------------------------ --- 10/11 [google-generativeai]\n",
      "   ------------------------------------ --- 10/11 [google-generativeai]\n",
      "   ------------------------------------ --- 10/11 [google-generativeai]\n",
      "   ---------------------------------------- 11/11 [google-generativeai]\n",
      "\n",
      "Successfully installed google-ai-generativelanguage-0.6.15 google-api-core-2.28.1 google-api-python-client-2.185.0 google-auth-httplib2-0.2.0 google-generativeai-0.8.5 googleapis-common-protos-1.71.0 grpcio-1.76.0 grpcio-status-1.71.2 httplib2-0.31.0 proto-plus-1.26.1 uritemplate-4.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install google-generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90a57004-29ae-43d1-8042-0002fb9ec857",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\".env\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"GOOGLE_API_KEY=AIzaSyCi99NkTULytK4F4NKRyQDbfyVkyv-Dgso\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4260e49b-7462-4565-9cb9-9a519cd71483",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! Yes, I am here and ready to assist you. What can I help you with today?\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import google.generativeai as genai\n",
    "\n",
    "# Load your .env file (optional if key is already set)\n",
    "load_dotenv()\n",
    "\n",
    "# Or set the API key manually\n",
    "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyCi99NkTULytK4F4NKRyQDbfyVkyv-Dgso\"\n",
    "\n",
    "# Configure Gemini\n",
    "genai.configure(api_key=os.getenv(\"GOOGLE_API_KEY\"))\n",
    "\n",
    "# Use a supported model (from your list)\n",
    "model = genai.GenerativeModel(\"gemini-2.5-flash\")\n",
    "\n",
    "# Test\n",
    "response = model.generate_content(\"Hello Gemini 2.5, are you working?\")\n",
    "print(response.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "beb81347-f115-44bc-9a2c-04a28ae877b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: google-generativeai in c:\\users\\sukanya das\\appdata\\roaming\\python\\python310\\site-packages (0.8.5)\n",
      "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in c:\\users\\sukanya das\\appdata\\roaming\\python\\python310\\site-packages (from google-generativeai) (0.6.15)\n",
      "Requirement already satisfied: google-api-core in c:\\users\\sukanya das\\appdata\\roaming\\python\\python310\\site-packages (from google-generativeai) (2.28.1)\n",
      "Requirement already satisfied: google-api-python-client in c:\\users\\sukanya das\\appdata\\roaming\\python\\python310\\site-packages (from google-generativeai) (2.185.0)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in c:\\users\\sukanya das\\appdata\\roaming\\python\\python310\\site-packages (from google-generativeai) (2.42.0)\n",
      "Requirement already satisfied: protobuf in c:\\users\\sukanya das\\appdata\\roaming\\python\\python310\\site-packages (from google-generativeai) (5.29.4)\n",
      "Requirement already satisfied: pydantic in c:\\users\\sukanya das\\appdata\\roaming\\python\\python310\\site-packages (from google-generativeai) (2.12.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\sukanya das\\appdata\\roaming\\python\\python310\\site-packages (from google-generativeai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\sukanya das\\appdata\\roaming\\python\\python310\\site-packages (from google-generativeai) (4.15.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in c:\\users\\sukanya das\\appdata\\roaming\\python\\python310\\site-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in c:\\users\\sukanya das\\appdata\\roaming\\python\\python310\\site-packages (from google-api-core->google-generativeai) (1.71.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.18.0 in c:\\users\\sukanya das\\appdata\\roaming\\python\\python310\\site-packages (from google-api-core->google-generativeai) (2.32.3)\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in c:\\users\\sukanya das\\appdata\\roaming\\python\\python310\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.76.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in c:\\users\\sukanya das\\appdata\\roaming\\python\\python310\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.2)\n",
      "Requirement already satisfied: cachetools<7.0,>=2.0.0 in c:\\users\\sukanya das\\appdata\\roaming\\python\\python310\\site-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\sukanya das\\appdata\\roaming\\python\\python310\\site-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\sukanya das\\appdata\\roaming\\python\\python310\\site-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sukanya das\\appdata\\roaming\\python\\python310\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sukanya das\\appdata\\roaming\\python\\python310\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sukanya das\\appdata\\roaming\\python\\python310\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sukanya das\\appdata\\roaming\\python\\python310\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2025.1.31)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in c:\\users\\sukanya das\\appdata\\roaming\\python\\python310\\site-packages (from rsa<5,>=3.1.4->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
      "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in c:\\users\\sukanya das\\appdata\\roaming\\python\\python310\\site-packages (from google-api-python-client->google-generativeai) (0.31.0)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in c:\\users\\sukanya das\\appdata\\roaming\\python\\python310\\site-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in c:\\users\\sukanya das\\appdata\\roaming\\python\\python310\\site-packages (from google-api-python-client->google-generativeai) (4.2.0)\n",
      "Requirement already satisfied: pyparsing<4,>=3.0.4 in c:\\users\\sukanya das\\appdata\\roaming\\python\\python310\\site-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\sukanya das\\appdata\\roaming\\python\\python310\\site-packages (from pydantic->google-generativeai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.4 in c:\\users\\sukanya das\\appdata\\roaming\\python\\python310\\site-packages (from pydantic->google-generativeai) (2.41.4)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\sukanya das\\appdata\\roaming\\python\\python310\\site-packages (from pydantic->google-generativeai) (0.4.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\sukanya das\\appdata\\roaming\\python\\python310\\site-packages (from tqdm->google-generativeai) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U google-generativeai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f7fe4e3-260c-4919-8102-43e49d4b3e6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/embedding-gecko-001\n",
      "models/gemini-2.5-pro-preview-03-25\n",
      "models/gemini-2.5-flash-preview-05-20\n",
      "models/gemini-2.5-flash\n",
      "models/gemini-2.5-flash-lite-preview-06-17\n",
      "models/gemini-2.5-pro-preview-05-06\n",
      "models/gemini-2.5-pro-preview-06-05\n",
      "models/gemini-2.5-pro\n",
      "models/gemini-2.0-flash-exp\n",
      "models/gemini-2.0-flash\n",
      "models/gemini-2.0-flash-001\n",
      "models/gemini-2.0-flash-exp-image-generation\n",
      "models/gemini-2.0-flash-lite-001\n",
      "models/gemini-2.0-flash-lite\n",
      "models/gemini-2.0-flash-preview-image-generation\n",
      "models/gemini-2.0-flash-lite-preview-02-05\n",
      "models/gemini-2.0-flash-lite-preview\n",
      "models/gemini-2.0-pro-exp\n",
      "models/gemini-2.0-pro-exp-02-05\n",
      "models/gemini-exp-1206\n",
      "models/gemini-2.0-flash-thinking-exp-01-21\n",
      "models/gemini-2.0-flash-thinking-exp\n",
      "models/gemini-2.0-flash-thinking-exp-1219\n",
      "models/gemini-2.5-flash-preview-tts\n",
      "models/gemini-2.5-pro-preview-tts\n",
      "models/learnlm-2.0-flash-experimental\n",
      "models/gemma-3-1b-it\n",
      "models/gemma-3-4b-it\n",
      "models/gemma-3-12b-it\n",
      "models/gemma-3-27b-it\n",
      "models/gemma-3n-e4b-it\n",
      "models/gemma-3n-e2b-it\n",
      "models/gemini-flash-latest\n",
      "models/gemini-flash-lite-latest\n",
      "models/gemini-pro-latest\n",
      "models/gemini-2.5-flash-lite\n",
      "models/gemini-2.5-flash-image-preview\n",
      "models/gemini-2.5-flash-image\n",
      "models/gemini-2.5-flash-preview-09-2025\n",
      "models/gemini-2.5-flash-lite-preview-09-2025\n",
      "models/gemini-robotics-er-1.5-preview\n",
      "models/gemini-2.5-computer-use-preview-10-2025\n",
      "models/embedding-001\n",
      "models/text-embedding-004\n",
      "models/gemini-embedding-exp-03-07\n",
      "models/gemini-embedding-exp\n",
      "models/gemini-embedding-001\n",
      "models/aqa\n",
      "models/imagen-3.0-generate-002\n",
      "models/imagen-4.0-generate-preview-06-06\n",
      "models/imagen-4.0-ultra-generate-preview-06-06\n",
      "models/imagen-4.0-generate-001\n",
      "models/imagen-4.0-ultra-generate-001\n",
      "models/imagen-4.0-fast-generate-001\n",
      "models/veo-2.0-generate-001\n",
      "models/veo-3.0-generate-preview\n",
      "models/veo-3.0-fast-generate-preview\n",
      "models/veo-3.0-generate-001\n",
      "models/veo-3.0-fast-generate-001\n",
      "models/veo-3.1-generate-preview\n",
      "models/veo-3.1-fast-generate-preview\n",
      "models/gemini-2.0-flash-live-001\n",
      "models/gemini-live-2.5-flash-preview\n",
      "models/gemini-2.5-flash-live-preview\n",
      "models/gemini-2.5-flash-native-audio-latest\n",
      "models/gemini-2.5-flash-native-audio-preview-09-2025\n"
     ]
    }
   ],
   "source": [
    "for m in genai.list_models():\n",
    "    print(m.name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b1ae9912-5a71-4f12-835b-9bd6e1bb0d63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting yt-dlp\n",
      "  Downloading yt_dlp-2025.10.22-py3-none-any.whl.metadata (176 kB)\n",
      "Downloading yt_dlp-2025.10.22-py3-none-any.whl (3.2 MB)\n",
      "   ---------------------------------------- 0.0/3.2 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 0.3/3.2 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 0.5/3.2 MB 2.1 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 1.0/3.2 MB 1.6 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 1.3/3.2 MB 1.5 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 1.3/3.2 MB 1.5 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 1.8/3.2 MB 1.4 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 2.1/3.2 MB 1.4 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 2.4/3.2 MB 1.4 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 2.6/3.2 MB 1.3 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 2.9/3.2 MB 1.3 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 3.1/3.2 MB 1.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 3.2/3.2 MB 1.3 MB/s  0:00:02\n",
      "Installing collected packages: yt-dlp\n",
      "Successfully installed yt-dlp-2025.10.22\n"
     ]
    }
   ],
   "source": [
    "!pip install yt-dlp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4573444d-ea36-45b5-be8f-5193523fefd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: moviepy in c:\\users\\sukanya das\\appdata\\roaming\\python\\python310\\site-packages (2.2.1)\n",
      "Requirement already satisfied: decorator<6.0,>=4.0.2 in c:\\users\\sukanya das\\appdata\\roaming\\python\\python310\\site-packages (from moviepy) (5.2.1)\n",
      "Requirement already satisfied: imageio<3.0,>=2.5 in c:\\users\\sukanya das\\appdata\\roaming\\python\\python310\\site-packages (from moviepy) (2.37.0)\n",
      "Requirement already satisfied: imageio_ffmpeg>=0.2.0 in c:\\users\\sukanya das\\appdata\\roaming\\python\\python310\\site-packages (from moviepy) (0.6.0)\n",
      "Requirement already satisfied: numpy>=1.25.0 in c:\\users\\sukanya das\\appdata\\roaming\\python\\python310\\site-packages (from moviepy) (2.2.6)\n",
      "Requirement already satisfied: proglog<=1.0.0 in c:\\users\\sukanya das\\appdata\\roaming\\python\\python310\\site-packages (from moviepy) (0.1.12)\n",
      "Requirement already satisfied: python-dotenv>=0.10 in c:\\users\\sukanya das\\appdata\\roaming\\python\\python310\\site-packages (from moviepy) (1.2.1)\n",
      "Requirement already satisfied: pillow<12.0,>=9.2.0 in c:\\users\\sukanya das\\appdata\\roaming\\python\\python310\\site-packages (from moviepy) (11.3.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\sukanya das\\appdata\\roaming\\python\\python310\\site-packages (from proglog<=1.0.0->moviepy) (4.67.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\sukanya das\\appdata\\roaming\\python\\python310\\site-packages (from tqdm->proglog<=1.0.0->moviepy) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install moviepy --upgrade\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9844c0ea-a1d1-4b2f-a418-fe8501da4857",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys, subprocess\n",
    "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"moviepy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4534ee05-7416-41f9-bae2-98cd673d8ecf",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'moviepy.editor'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01myt_dlp\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m YoutubeDL\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmoviepy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01meditor\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmp\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mspeech_recognition\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msr\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdownload_youtube_video\u001b[39m(url, output_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdownloaded_video.mp4\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'moviepy.editor'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from yt_dlp import YoutubeDL\n",
    "import moviepy.editor as mp\n",
    "import speech_recognition as sr\n",
    "\n",
    "def download_youtube_video(url, output_path=\"downloaded_video.mp4\"):\n",
    "    try:\n",
    "        ydl_opts = {\n",
    "            'format': 'best',\n",
    "            'outtmpl': output_path\n",
    "        }\n",
    "        with YoutubeDL(ydl_opts) as ydl:\n",
    "            ydl.download([url])\n",
    "        return output_path\n",
    "    except Exception as e:\n",
    "        return f\"Error downloading YouTube video: {e}\"\n",
    "\n",
    "def extract_audio_from_video(video_path, audio_path=\"temp_audio.wav\"):\n",
    "    try:\n",
    "        video = mp.VideoFileClip(video_path)\n",
    "        video.audio.write_audiofile(audio_path)\n",
    "        return audio_path\n",
    "    except Exception as e:\n",
    "        return f\"Error extracting audio: {e}\"\n",
    "\n",
    "def transcribe_audio(audio_path):\n",
    "    try:\n",
    "        recognizer = sr.Recognizer()\n",
    "        with sr.AudioFile(audio_path) as source:\n",
    "            audio = recognizer.record(source)\n",
    "        text = recognizer.recognize_google(audio)\n",
    "        return text\n",
    "    except Exception as e:\n",
    "        return f\"Error transcribing audio: {e}\"\n",
    "\n",
    "def youtube_to_text(url):\n",
    "    video_path = download_youtube_video(url)\n",
    "    if not os.path.exists(video_path):\n",
    "        return video_path  # Return error message\n",
    "\n",
    "    audio_path = extract_audio_from_video(video_path)\n",
    "    if not os.path.exists(audio_path):\n",
    "        return audio_path  # Return error message\n",
    "\n",
    "    transcript = transcribe_audio(audio_path)\n",
    "\n",
    "    # Optional cleanup\n",
    "    os.remove(audio_path)\n",
    "\n",
    "    return transcript\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21526cd9-fe0f-4d0f-a3ff-33ed67c61e05",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'youtube_to_text' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://youtu.be/sljF4t0nOk0?si=lOOvA7aYdz6DcL5N\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 2\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[43myoutube_to_text\u001b[49m(url)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(text)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'youtube_to_text' is not defined"
     ]
    }
   ],
   "source": [
    "url = \"https://youtu.be/sljF4t0nOk0?si=lOOvA7aYdz6DcL5N\"\n",
    "text = youtube_to_text(url)\n",
    "print(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd22ece6-7c44-431c-9c21-442baa30ddba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
